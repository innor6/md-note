bias vs variance

- high variance：随着训练样本的增加，test error 和 training error 始终有一个较大的 gap（前者不断下降，后者不断上升）
  - 增大训练集
  - 减少特征
- high bias：随着训练样本的增加，test error 和 training error 逐渐靠近，且收敛于一个较高的error值
  - 增加特征
  - 更换特征





- 是否在最优化正确的损失函数
  - 逻辑回归时使用不同的 λ 作为参数复杂度的惩罚权重
  - 改用SVM等其他算法
- 最优化损失函数的算法是否正确，能否收敛
  - 迭代更多次
  - 使用牛顿迭代法

例：假设一个算法已经最小化了损失函数，但是准确率低；同时存在另一个算法得到的参数虽然损失函数大，但是准确率高，则说明问题在于选择了错误的损失函数，最小化不代表准确率高；反之则问题在于最优化的算法。



error analysis

如果一个系统包括很多组件，可以分别对每个组件测试，以决定优先提升哪一组件的性能。如相比于使用组件的输出，使用人为的手动标注数据替换，看能对系统准确度有多大的提升，若提升很大，则说明组件还有改进空间。



ablative analysis

假设经过一些技巧，使得系统准确度从94%提升到了99%，想知道这些技巧里有效的是哪些？可以从99%开始，每次去除一个技巧，看准确度下降了多少

