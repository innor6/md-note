#### 内存空间

- 内核空间：由内核和所有进程共享，用户态下访问会导致页错误
- 栈
- 内存映射段：将文件内容直接映射到内存，如加载动态库
- 堆
- 静态数据段：未初始化的数据BSS、初始化的数据
- 代码段

**虚拟内存空间**：每个进程都有自己独立的虚拟地址空间，MMU通过TLB、页表将虚拟地址映射到真正的物理内存，每个进程一个页表。



#### 缓存/页面置换算法

- 最佳置换算法OPT（只是理论上的最佳，因为需要知道未来的请求）
- 先进先出
- 最近最久未使用LRU（根据过去的请求作为依据，模拟OPT，实现复杂）
- clock算法（模拟LRU，实现简单）



#### 进程和线程

进程：是运行状态的程序，是程序执行的实例。

线程：程序执行的最小单位。

1. 进程是资源分配的最小单位（内存、CPU）；线程是CPU调度和执行的最小单位；
2. 线程拥有独立的线程id、寄存器、栈、errno、信号掩码、优先级，但是共享数据段等其他资源；创建/销毁一个线程的代价较低；
3. 进程间切换的代价大，包括：用户态到内核态的切换、保存当前进程的状态（寄存器）、内存映像的改变、调度程序以及载入新程序、高速缓存失效。
4. 同样的，进程间通信较复杂。

为什么用线程：

1. fork进程的代价大：需要复制父进程的内存映像（就算有写时复制，代价还是大）。
2. 进程间通信复杂：包含了进程间切换，涉及到内核态的转换

页表、程序计数器、寄存器确定了一个进程的状态。



#### 线程同步

**互斥锁**：

提供互斥机制，防止同时访问某个共享变量。首先创建一个静态了互斥锁变量，然后在线程中对这个互斥锁变量使用`pthread_mutex_lock`、`pthread_mutex_unlock`，以互斥的访问修改某些其他变量。未得到锁的线程将会阻塞直到锁被释放。

**条件变量**：

提供信号机制。如当要不断重复检查某个共享变量的值是否满足某个条件时，要访问这个值必须先获取锁，若一直不满足，则会反复的进入临界区却什么也不做（轮询），浪费CPU时间。

配合互斥锁使用：

```c
// 主线程
// 互斥变量：cnt，通过互斥锁my_mutex来互斥访问
// 主线程需要检查cnt，但轮询会一直抢占互斥锁、cpu，不进入休眠，并发低
// 条件变量：my_cond，“关联”这个互斥锁my_mutex
// 当获取锁后发现cnt==0，就主动释放锁并阻塞，等待子线程将cnt++后发出信号，通知主线程，再唤醒
while (1) {
    pthread_mutex_lock(&my_mutex);
	while (cnt == 0) {
		pthread_cond_wait(&my_cond, &my_mutex);	//释放持有互斥锁，收到信号后返回，再次获得锁
	}
	... //处理
	pthread_mutex_unlock(&my_mutex);
}


// 子线程
// pthread_cond_signal唤醒等待在该条件变量上的单个线程
{
    pthread_mutex_lock(&my_mutex);
    ++cnt;
    pthread_cond_signal(&my_cond); //++cnt后，发送信号给条件变量my_cond，通知主线程目标变量已修改
    pthread_mutex_unlock(&my_mutex);
}
```

个人理解：收到信号后，`pthread_cond_wait`返回，主线程被唤醒，同时会再次尝试获取互斥锁；随后子线程释放锁，于是主线程得到锁。

注意：这里主线程中要把`pthread_cond_wait`包围在互斥锁中，从而可以保证信号不会丢失，因为信号总是在获得锁的线程中发出的，而线程能获得锁，说明主线程之前要么已经调用过`pthread_cond_wait`获取，要么还没进入过临界区。



#### 孤儿进程/僵尸进程

孤儿进程：父进程先结束，子进程变为孤儿进程，孤儿会变为init进程的子进程，由init进程进行回收。

僵尸进程：子进程先结束，父进程未调用wait、waitpid等待子进程结束，则子进程描述符会一直保存在系统中，资源无法回收。

fork：父进程中返回子进程pid，子进程返回0，出错返回-1。



#### 进程调度

批处理系统：先来先服务、短作业优先、剩余时间优先。

交互式系统：时间片轮转法、优先级队列、多级队列。



#### 进程间通信

- 匿名管道pipe：
  - 慢，容量有限，只能用于父子进程间通信；
  - 半双工，父进程创建两个fd[2]，fork后，父子各自关闭一个fd，从而一端固定读fd[0]一端固定写fd[1]；
  - FIFO
  - 读了就消耗
- FIFO：
  - 文件形式，有路径名
  - 又有管道特性
  - 可以多个客户进程向某个FIFO写，一个服务进程读
- 消息队列
  - 独立于收发进程，进程关闭后消息队列还在
  - 可以FIFO地读取消息，也可以读特定类型（编号）的消息
  - 第一次读时需要考虑可能有上一次没有读完的数据
- 信号量
  - 用于进程间同步
  - P、V操作，实现对信号量的加减，P请求时减少信号量，小于零则阻塞，直到V释放后被唤醒
  - 信号量通过key来标识
  - 配合共享内存使用
- 共享内存
  - 最快，但需要利用信号量来保持进程同步
  - 创建共享内存后，需要连接（映射到进程的地址空间）才能访问



#### IO模型

阻塞 IO、非阻塞 IO（读写失败立即返回，轮询）、IO 复用模型（select）、信号驱动、异步IO



#### 死锁

必要条件：

1. 资源是互斥的。
2. 进程是不可剥夺的：资源只能等待进程自己主动释放
3. 请求和保持：进程保持资源的同时去请求其他资源，阻塞了也不释放
4. 循环等待：等待的进程形成环路

**死锁避免**

操作系统给进程分配资源前，进行动态检查。使用银行家算法检查某个分配序列是否是安全序列，系统是否处于安全状态。

银行家算法：需要知道各个进程对资源的当前占有量、最大占有量、当前需求量，如果将当前剩余的资源分配给某个进程，使其可以运行完毕，随后归还所有资源，然后继续分配给其他进程，这样依次下去，能让所有进程的执行完毕，则是安全的。

**死锁预防**

破坏死锁的四个条件

1. 破坏“不可剥夺”条件：一个进程不能获得所需要的全部资源时便处于等待状态，等待期间他占有的资源将被隐式的释放重新加入到 系统的资源列表中，可以被其他的进程使用，而等待的进程只有重新获得自己原有的资源以及新申请的资源才可以重新启动，执行。
2. 破坏”请求与保持条件“：第一种方法静态分配即每个进程在开始执行时就申请他所需要的全部资源（2PL）。第二种是动态分配即每个进程在申请所需要的资源时他本身不占用系统资源。
3. 破坏“循环等待”条件：采用资源有序分配其基本思想是将系统中的所有资源顺序编号，将紧缺的，稀少的采用较大的编号，在申请资源时必须按照编号的顺序进行，（按顺序加锁）一个进程只有获得较小编号的资源后才能申请较大编号的资源。

**死锁检测**





#### 内核态切换

进入内核态的原因：

1. 系统调用
2. 异常（缺页异常）
3. 中断（IO完成导致的中断）

用户态到内核态的步骤主要包括：

1. 从当前进程的描述符中提取其内核栈的ss0及esp0信息。

   （其实就算保存寄存器。ss：栈顶指针，esp：栈帧指针）

2. 使用ss0和esp0指向的内核栈将当前进程的cs,eip，eflags，ss,esp信息保存起来，这个过程也完成了由用
   户栈找到内核栈的切换过程，同时保存了被暂停执行的程序的下一条指令。

3. 将先前由中断向量检索得到的中断处理程序的cs，eip信息装入相应的寄存器，开始执行中断处理程序，这
   时就转到了内核态的程序执行了





#### IO模型

- 阻塞 I/O（blocking IO）：调用read，阻塞，内核读取数据到内核缓冲区，内核将数据拷贝到用户内存，返回。
- 非阻塞 I/O（nonblocking IO）：调用read，若内核未准备好数据，直接返回error；若内核准备好了，阻塞，将数据拷贝到用户内存，返回。（只有内核准备好数据了才会阻塞，需要应用程序主动的轮询）
- I/O 多路复用（ IO multiplexing）：调用select，进入阻塞，内核不断的轮询 select 所选择的 fd，当有一个fd就绪时，返回。用户再调用read，内核将数据拷贝到用户内存。（用了两个系统调用，优势是可以同时等待多个fd，即一个进程就可以处理多个连接）
- 信号驱动 I/O（ signal driven IO）
- 异步 I/O（asynchronous IO）：调用aio_read，通知内核读取数据，返回。内核自己偷偷完成数据的准备、数据的拷贝，然后再利用信号通知进程数据已经拷贝到用户内存。

[IO多路复用](https://blog.csdn.net/lcalqf/article/details/79554390)